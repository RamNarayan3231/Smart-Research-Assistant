
# ğŸ“š Smart Research Assistant

An AI-powered web application that allows users to upload research documents (PDF/TXT), ask questions, receive AI-generated answers with justifications, and evaluate their own understanding through generated challenge questions and feedback.

## ğŸ”§ Features

âœ… Upload PDF or TXT documents

âœ… AI-generated document summary

âœ… Ask contextual questions about the document

âœ… Generate challenge questions to test comprehension

âœ… Answer evaluation with scoring and ideal answers

âœ… Clean UI using Streamlit

âœ… FastAPI backend with LLM integration via OpenRouter


## ğŸš€ Demo


![Screenshot 2025-07-08 022512](https://github.com/user-attachments/assets/b56fd6e5-a245-491f-a1eb-7f0ed7154327)

![Screenshot 2025-07-08 022853](https://github.com/user-attachments/assets/f9e723c0-86c1-4293-876d-5330620a9f26)

![Screenshot 2025-07-08 020632](https://github.com/user-attachments/assets/4dbff42b-cad7-4e5d-9e28-79e873f6736e)

![Screenshot 2025-07-08 042502](https://github.com/user-attachments/assets/8fc1eb1a-1856-426b-bcf5-ecb33798cef7)

![Screenshot 2025-07-08 022947](https://github.com/user-attachments/assets/4c946bc7-b2d2-4218-b397-bd10783b9325)

![Screenshot 2025-07-08 024621](https://github.com/user-attachments/assets/fa57cf14-b800-4e51-91ac-073f5b54c185)



## ğŸ“ Project Structure

```
research-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI backend entry point
â”‚   â”œâ”€â”€ document_processor.py  # PDF/TXT parsing and summarization
â”‚   â”œâ”€â”€ openrouter_llm.py      # Custom LLM interface using OpenRouter
â”‚   â”œâ”€â”€ qa_system.py           # Handles QA, challenge generation, evaluation
â”‚   â””â”€â”€ utils.py               # Utilities (text cleaning, word count, etc.)
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                 # Streamlit frontend app
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                       # Environment variables
â””â”€â”€ venv/                      # Virtual environment (optional)
```


## ğŸš€ How to Run

### 1. Clone the Repository
```
git clone https://github.com/RAmNarayan3231/Smart-Research-Assistant.git
cd research-assistant
```
### 2. Set up Environment
Create a .env file in the root directory and include the following:
```
OPENROUTER_API_KEY=your_openrouter_api_key
OPENROUTER_MODEL=openai/gpt-4.1-nano
YOUR_SITE_URL=http://localhost:8501
YOUR_SITE_NAME=Smart Research Assistant
```
### 3. Install Dependencies
```
pip install -r requirements.txt
```


## ğŸ–¥ï¸ Running the App

### Step 1: Start Backend
```
uvicorn main:app --reload
```
It will start at http://localhost:8000.

### Step 2: Start Frontend
```
streamlit run frontend/app.py
```
It will launch the frontend at http://localhost:8501.

# ğŸ› ï¸ API Endpoints

Method	Endpoint	Description
POST	/upload/	Upload and process a document
POST	/ask/{doc_id}	Ask a question about a document
GET	/challenge/{doc_id}	Generate challenge questions
POST	/evaluate/{doc_id}/{id}	Evaluate user's answer
GET	/	API homepage



## ğŸ“š Technologies 

Python 3.10+
Streamlit â€“ for interactive frontend
FastAPI â€“ for robust backend APIs
LangChain â€“ for chaining LLM prompts
OpenRouter â€“ LLM API provider
PyPDF2 â€“ for PDF reading
Pydantic â€“ for data validation

## ğŸ§  Future Improvements

âœ… Semantic search for better QA context
âœ… PDF OCR (for scanned PDFs)
âœ… Save sessions and history
âœ… MCQ generation
âœ… Multilingual support

## ğŸ¤ Contributing
Feel free to fork the repo and submit pull requests. For major changes, open an issue first.

